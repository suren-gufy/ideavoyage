// Using type definitions directly to avoid module import issues
interface VercelRequest {
  method?: string;
  url?: string;
  body?: any;
  cookies?: Record<string, string>;
  headers?: Record<string, string>;
  query?: Record<string, string | string[]>;
}

// Safe database integration - won't fail if Supabase isn't available
let DatabaseService: any = null;

// Initialize database service if available
async function initializeDatabase() {
  if (process.env.SUPABASE_URL && process.env.SUPABASE_ANON_KEY && !DatabaseService) {
    try {
      const supabaseModule = await import('../lib/supabase.js');
      DatabaseService = supabaseModule.DatabaseService;
      console.log('‚úÖ Supabase database service initialized');
    } catch (error) {
      console.warn('‚ö†Ô∏è Supabase initialization failed, continuing without database:', (error as Error).message);
      DatabaseService = null;
    }
  }
}

// Simple type for analysis records
interface AnalysisRecord {
  id?: string;
  created_at?: string;
  idea: string;
  industry?: string;
  target_audience?: string;
  country?: string;
  analysis_results: any;
  data_source: string;
  analysis_confidence: string;
  overall_score: number;
  viability_score: number;
  user_session?: string;
}



interface VercelResponse {
  status: (statusCode: number) => VercelResponse;
  json: (jsonBody: any) => VercelResponse;
  send: (body: any) => VercelResponse;
  setHeader: (name: string, value: string) => void;
  end: () => void;
}

// Utility: clamp numbers
const clamp = (val: number, min: number, max: number) => Math.min(max, Math.max(min, val));

interface RawRedditPost {
  title: string;
  selftext?: string;
  score: number;
  num_comments: number;
  created_utc: number;
  permalink: string;
  subreddit: string;
  // 'reddit' for real fetched data, 'synthetic' for internally generated filler
  source?: 'reddit' | 'synthetic';
}

// Inline Reddit OAuth functionality to avoid import issues
async function getRedditOAuthToken(clientId: string, clientSecret: string): Promise<string | null> {
  try {
    // Always use Buffer.from for Node.js serverless compatibility
    const credentials = `${clientId}:${clientSecret}`;
    const auth = Buffer.from(credentials, 'utf-8').toString('base64');
    
    console.log('üîë Attempting Reddit OAuth...');
    console.log('üîë Client ID length:', clientId.length);
    console.log('üîë Client Secret length:', clientSecret.length);
    console.log('üîë Auth header length:', auth.length);
    
    const response = await fetch('https://www.reddit.com/api/v1/access_token', {
      method: 'POST',
      headers: {
        'Authorization': `Basic ${auth}`,
        'User-Agent': 'IdeaVoyage/1.0 (by /u/ideavoyage)',
        'Content-Type': 'application/x-www-form-urlencoded'
      },
      body: 'grant_type=client_credentials'
    });
    
    console.log('üîë Reddit OAuth response status:', response.status);
    const headerObj: Record<string, string> = {};
    response.headers.forEach((value, key) => {
      headerObj[key] = value;
    });
    console.log('üîë Response headers:', JSON.stringify(headerObj));
    
    if (response.ok) {
      const tokenData = await response.json() as any;
      console.log('‚úÖ Reddit OAuth SUCCESS! Token type:', tokenData.token_type);
      console.log('‚úÖ Token scope:', tokenData.scope);
      console.log('‚úÖ Token expires in:', tokenData.expires_in, 'seconds');
      return tokenData.access_token;
    } else {
      const errorText = await response.text();
      console.error('‚ùå Reddit OAuth FAILED:', response.status, response.statusText);
      console.error('‚ùå Error response:', errorText);
      return null;
    }
  } catch (error) {
    console.error('‚ùå Reddit OAuth EXCEPTION:', (error as Error).message);
    console.error('‚ùå OAuth Error Stack:', (error as Error).stack);
    return null;
  }
}

async function fetchRedditPosts(subreddit: string, token: string, limit: number = 25): Promise<any[]> {
  try {
    const response = await fetch(`https://oauth.reddit.com/r/${subreddit}/top?limit=${limit}&t=week`, {
      headers: {
        'Authorization': `Bearer ${token}`,
        'User-Agent': 'IdeaVoyage/1.0 (by /u/ideavoyage)'
      }
    });
    
    if (!response.ok) {
      console.warn(`‚ùå Reddit API error for r/${subreddit}:`, response.status);
      return [];
    }
    
    const data = await response.json() as any;
    const posts = (data?.data?.children || [])
      .map((c: any) => c.data)
      .filter((p: any) => p.title)
      .slice(0, limit);
    
    console.log(`‚úÖ OAuth: Got ${posts.length} posts from r/${subreddit}`);
    return posts;
  } catch (error) {
    console.error(`‚ùå OAuth failed for r/${subreddit}:`, (error as Error).message);
    return [];
  }
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  // CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');
  if (req.method === 'OPTIONS') return res.status(200).end();

  try {
    const url = req.url || '';

    // Handle different GET routes
    if (req.method === 'GET') {
      // Premium status endpoint
      if (url.includes('/premium-status') || url.endsWith('/premium-status')) {
        return res.json({
          isPremium: false,
          plan: 'free',
          features: {
            basicAnalysis: true,
            advancedAnalysis: false,
            unlimitedReports: false,
            prioritySupport: false
          },
          message: 'Free tier - upgrade for advanced features'
        });
      }
      
      // Reddit OAuth endpoints for real data access
      if (url.includes('/reddit/auth')) {
        console.log('üîë Reddit OAuth auth endpoint accessed:', url);
        // Generate Reddit OAuth URL
        const clientId = process.env.REDDIT_CLIENT_ID || 'demo_client_id';
        const redirectUri = process.env.REDDIT_REDIRECT_URI || 'https://ideavoyage.vercel.app/api/reddit/callback';
        const state = Math.random().toString(36).substring(7);
        
        const authUrl = `https://www.reddit.com/api/v1/authorize?client_id=${clientId}&response_type=code&state=${state}&redirect_uri=${encodeURIComponent(redirectUri)}&duration=temporary&scope=read`;
        
        res.setHeader('Location', authUrl);
        return res.status(302).send('Redirecting to Reddit...');
      }
      
      if (url.includes('/reddit/callback')) {
        console.log('üìû Reddit OAuth callback endpoint accessed:', url);
        const code = req.query?.code as string;
        const error = req.query?.error as string;
        
        if (error) {
          return res.json({ 
            success: false, 
            error: `Reddit declined authorization: ${error}`,
            message: 'Reddit OAuth was cancelled or failed. You can still use demo mode.'
          });
        }
        
        if (code) {
          // In a real implementation, exchange code for token here
          return res.json({
            success: true,
            message: 'Reddit authentication successful! Real market data will be available once OAuth integration is completed.',
            code: code.substring(0, 10) + '...',
            nextSteps: 'Contact support to complete Reddit API integration with your authorization.'
          });
        }
        
        return res.status(400).json({ 
          success: false, 
          error: 'No authorization code received' 
        });
      }

      // Reddit OAuth test endpoint
      if (url.includes('/test-reddit-oauth') || url.includes('test-oauth')) {
        try {
          console.log('üß™ Reddit OAuth test endpoint accessed');
          const clientId = process.env.REDDIT_CLIENT_ID;
          const clientSecret = process.env.REDDIT_CLIENT_SECRET;
          
          if (!clientId || !clientSecret) {
            return res.json({
              success: false,
              error: 'Reddit credentials not found',
              clientId: clientId ? `Present (${clientId.length} chars)` : 'Missing',
              clientSecret: clientSecret ? `Present (${clientSecret.length} chars)` : 'Missing'
            });
          }
          
          console.log('üß™ Testing simple token request...');
          const token = await getRedditOAuthToken(clientId, clientSecret);
          
          return res.json({
            success: !!token,
            message: token ? 'Reddit OAuth working!' : 'Failed to get token',
            tokenLength: token?.length || 0,
            timestamp: new Date().toISOString()
          });
          
        } catch (error) {
          console.error('üß™ Test endpoint error:', error);
          return res.json({
            success: false,
            error: (error as Error).message,
            name: (error as Error).name,
            stack: (error as Error).stack?.substring(0, 500)
          });
        }
      }

      // Health check (default GET)
      const hasPerplexityKey = process.env.PERPLEXITY_API_KEY && process.env.PERPLEXITY_API_KEY.trim().length > 0;
      
      // Test Reddit API connectivity
      let redditTest = 'unknown';
      try {
        // Create two abort signals: one for timeout and one for manual abortion if needed
        // Create a timeout signal using type assertion to avoid conflicts
        const timeoutSignal = (AbortSignal as any).timeout(5000);
        const controller = new AbortController();
        
        // Combine signals using AbortSignal.any() with type assertion
        // This avoids TypeScript errors from conflicting DOM/Node type definitions
        const combinedSignal = (AbortSignal as any).any([
          timeoutSignal,
          controller.signal
        ]);
        
        // Try multiple Reddit access methods
        let testResponse;
        try {
          // Method 1: Direct JSON endpoint
          testResponse = await fetch('https://www.reddit.com/r/startups/hot.json?limit=1', {
            headers: { 
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
              'Accept': 'application/json',
              'Accept-Language': 'en-US,en;q=0.9',
              'Cache-Control': 'no-cache'
            },
            signal: combinedSignal
          });
        } catch (e1) {
          // Method 2: Alternative endpoint
          try {
            testResponse = await fetch('https://old.reddit.com/r/startups/hot.json?limit=1', {
              headers: { 
                'User-Agent': 'Mozilla/5.0 (compatible; Market Research Tool/1.0)',
                'Accept': 'application/json'
              },
              signal: combinedSignal
            });
          } catch (e2) {
            throw e1; // Throw original error
          }
        }
        redditTest = testResponse.ok ? 'working' : `error_${testResponse.status}`;
      } catch (err) {
        redditTest = `failed_${(err as Error).message.substring(0,50)}`;
      }
      
      return res.json({
        message: 'IdeaVoyage API live',
        mode: hasPerplexityKey ? 'enhanced' : 'heuristic',
        perplexity_available: hasPerplexityKey,
        reddit_test: redditTest,
        reddit_oauth_available: !!(process.env.REDDIT_CLIENT_ID && process.env.REDDIT_CLIENT_SECRET),
        reddit_client_id_length: process.env.REDDIT_CLIENT_ID?.length || 0,
        reddit_client_secret_length: process.env.REDDIT_CLIENT_SECRET?.length || 0,
        reddit_client_id_preview: process.env.REDDIT_CLIENT_ID?.substring(0, 8) + '...' || 'missing',
        reddit_client_secret_preview: process.env.REDDIT_CLIENT_SECRET?.substring(0, 15) + '...' || 'missing',
        env_key_length: process.env.PERPLEXITY_API_KEY ? process.env.PERPLEXITY_API_KEY.length : 0,
        env_key_start: process.env.PERPLEXITY_API_KEY ? process.env.PERPLEXITY_API_KEY.substring(0, 20) + '...' : 'missing',
        timestamp: new Date().toISOString(),
        version: "2025-30-01-reddit-debug",
        url
      });
    }

    // Only allow POST for analysis
    if (req.method !== 'POST') {
      return res.status(405).json({ 
        error: 'Method not allowed', 
        allowed: ['GET', 'POST'],
        received: req.method 
      });
    }

    // Enhanced input validation with better error handling
    let body;
    try {
      body = req.body || {};
    } catch (parseError) {
      return res.status(400).json({ 
        error: 'Invalid JSON in request body',
        detail: 'Please send valid JSON data'
      });
    }

    const { idea, industry, targetAudience, country = 'global', platform = 'web-app', fundingMethod = 'self-funded', timeRange = 'month' } = body;
    
    // Comprehensive input validation
    if (!idea) {
      return res.status(400).json({ 
        error: 'Missing required field: idea',
        required: 'Please provide a startup idea in the "idea" field.'
      });
    }
    
    if (typeof idea !== 'string') {
      return res.status(400).json({ 
        error: 'Invalid idea format',
        detail: 'The "idea" field must be a string.'
      });
    }
    
    const trimmedIdea = idea.trim();
    if (trimmedIdea.length < 10) {
      return res.status(400).json({ 
        error: 'Idea too short',
        detail: 'Please provide a more detailed description (at least 10 characters).'
      });
    }

    if (trimmedIdea.length > 1000) {
      return res.status(400).json({ 
        error: 'Idea too long',
        detail: 'Please keep your idea description under 1000 characters.'
      });
    }

      try {
        // Initialize database service early (non-blocking)
        initializeDatabase().catch(err => console.warn('Database initialization failed:', err));
        
        console.log('üöÄ Starting performRealAnalysis...');
        const startTime = Date.now();
        
        const result = await performRealAnalysis({ 
          idea: trimmedIdea, 
          industry, 
          targetAudience, 
          country, 
          platform, 
          fundingMethod, 
          timeRange 
        });
        
        const duration = Date.now() - startTime;
        console.log(`‚úÖ Analysis completed successfully in ${duration}ms`);

        // Save analysis to database (if available)
        if (DatabaseService) {
          try {
            await initializeDatabase();
            if (DatabaseService) {
              const resultAny = result as any;
              const analysisRecord = {
                idea: trimmedIdea,
                industry: industry || undefined,
                target_audience: targetAudience || undefined,
                country: country || 'global',
                analysis_results: result,
                data_source: resultAny.data_source || 'unknown',
                analysis_confidence: resultAny.analysis_confidence || 'unknown',
                overall_score: result.overall_score,
                viability_score: result.viability_score,
                user_session: req.headers?.['x-session-id'] || undefined
              };

              const savedRecord = await DatabaseService.saveAnalysis(analysisRecord);
              if (savedRecord) {
                console.log(`üíæ Analysis saved to database with ID: ${savedRecord.id}`);
                (result as any).database_id = savedRecord.id;
              }
            }
          } catch (dbError) {
            console.error('‚ö†Ô∏è Database save failed, continuing with response:', dbError);
          }
        }

        return res.json(result);
      } catch (analysisError) {
        console.error('‚ùå Analysis error:', analysisError);
        console.error('‚ùå Error stack:', (analysisError as Error).stack);
        // Generate emergency fallback result based on the idea
        const fallbackResult = generateEmergencyAnalysis(trimmedIdea, industry, targetAudience);
        
        // Save fallback analysis to database (if available)
        if (DatabaseService) {
          try {
            await initializeDatabase();
            if (DatabaseService) {
              const fallbackAny = fallbackResult as any;
              const analysisRecord = {
                idea: trimmedIdea,
                industry: industry || undefined,
                target_audience: targetAudience || undefined,
                country: country || 'global',
                analysis_results: fallbackResult,
                data_source: fallbackAny.data_source || 'fallback',
                analysis_confidence: fallbackAny.analysis_confidence || 'low',
                overall_score: fallbackResult.overall_score,
                viability_score: fallbackResult.viability_score,
                user_session: req.headers?.['x-session-id'] || undefined
              };

              const savedRecord = await DatabaseService.saveAnalysis(analysisRecord);
              if (savedRecord) {
                console.log(`üíæ Fallback analysis saved to database with ID: ${savedRecord.id}`);
                (fallbackResult as any).database_id = savedRecord.id;
              }
            }
          } catch (dbError) {
            console.error('‚ö†Ô∏è Database save failed for fallback, continuing with response:', dbError);
          }
        }
        
        return res.json(fallbackResult);
      }

  } catch (err) {
    console.error('Fatal API error', err);
    // Even in case of fatal error, try to return a valid analysis structure
    try {
      const idea = (req.body && typeof req.body === 'object' && req.body.idea) || 'startup idea';
      const industry = (req.body && typeof req.body === 'object' && req.body.industry) || undefined;
      const targetAudience = (req.body && typeof req.body === 'object' && req.body.targetAudience) || undefined;
      const fallbackResult = generateEmergencyAnalysis(idea, industry, targetAudience);
      return res.json(fallbackResult);
    } catch {
      return res.status(500).json({ 
        error: 'Internal server error', 
        detail: err instanceof Error ? err.message : String(err),
        timestamp: new Date().toISOString()
      });
    }
  }
}

// Generate realistic synthetic posts when Reddit data is insufficient
function generateRealisticSyntheticPosts(idea: string, industry: string, subreddit: string): RawRedditPost[] {
  const keywords = idea.toLowerCase().split(/\s+/).filter(w => w.length > 3).slice(0, 3);
  const isAI = /\b(ai|artificial|intelligence|machine|learning|algorithm|neural|nlp|gpt|llm)\b/i.test(idea);
  const isFitness = /\b(fitness|gym|workout|health|exercise|training|nutrition|athlete)\b/i.test(idea);
  
  const syntheticTemplates = [
    {
      title: `Has anyone tried ${keywords[0] || 'something'} for ${industry || 'business'}?`,
      selftext: `Looking for alternatives to existing solutions in ${industry || 'this space'}. Current options seem limited and expensive.`,
      score: Math.floor(Math.random() * 85) + 15,
      comments: Math.floor(Math.random() * 20) + 3
    },
    {
      title: `Thoughts on ${idea.split(' ').slice(0, 4).join(' ')}?`,
      selftext: `Been researching this for a while. Market seems ready but execution is challenging. Anyone with experience?`,
      score: Math.floor(Math.random() * 65) + 18,
      comments: Math.floor(Math.random() * 28) + 6
    },
    {
      title: `Why isn't there a good solution for ${keywords.join(' ')} yet?`,
      selftext: `Every existing option I've tried has major limitations. There's definitely demand but no one has nailed the execution.`,
      score: Math.floor(Math.random() * 120) + 25,
      comments: Math.floor(Math.random() * 35) + 8
    },
    {
      title: `Just launched our ${industry || 'startup'} MVP - early feedback?`,
      selftext: `After months of development, we're looking for honest feedback. Trying to solve the ${keywords[0] || 'problem'} problem differently.`,
      score: Math.floor(Math.random() * 48) + 12,
      comments: Math.floor(Math.random() * 25) + 4
    },
    {
      title: `Market research: How much would you pay for ${keywords[0] || 'this'} solution?`,
      selftext: `Validating pricing for our upcoming launch. Current alternatives are either too expensive or too basic.`,
      score: Math.floor(Math.random() * 70) + 16,
      comments: Math.floor(Math.random() * 30) + 7
    },
    {
      title: `Struggling with ${keywords[0] || 'current'} tools - any recommendations?`,
      selftext: `Current solutions don't meet our needs. Looking for something more tailored to ${industry || 'our use case'}. Budget is flexible for the right solution.`,
      score: Math.floor(Math.random() * 90) + 20,
      comments: Math.floor(Math.random() * 22) + 5
    },
    {
      title: `${industry || 'Business'} owners: what's your biggest pain point with ${keywords[0] || 'operations'}?`,
      selftext: `Trying to understand the market better. What problems do you face daily that tech could solve?`,
      score: Math.floor(Math.random() * 110) + 30,
      comments: Math.floor(Math.random() * 40) + 12
    },
    {
      title: `Anyone else excited about the potential of ${keywords.slice(0,2).join(' ')}?`,
      selftext: `Seeing a lot of innovation in this space lately. The market timing seems perfect for new solutions.`,
      score: Math.floor(Math.random() * 75) + 22,
      comments: Math.floor(Math.random() * 18) + 9
    }
  ];
  
  // Add industry-specific boost
  const industryBoosts = {
    ai: isAI ? 1.4 : 1.0,
    fitness: isFitness ? 1.2 : 1.0
  };
  const boost = Math.max(...Object.values(industryBoosts));
  
  return syntheticTemplates.slice(0, 4).map((template, i) => ({
    title: template.title,
    selftext: template.selftext,
    score: Math.floor(template.score * boost),
    num_comments: Math.floor(template.comments * boost),
    created_utc: Math.floor(Date.now() / 1000) - Math.floor(Math.random() * 86400 * 3), // Last 3 days
    permalink: `/r/${subreddit}/comments/${Date.now() + i}/synthetic_post/`,
    subreddit: subreddit,
    source: 'synthetic'
  }));
}

// Emergency fallback that always returns a valid analysis structure
function generateEmergencyAnalysis(idea: string, industry?: string, targetAudience?: string) {
  const ideaTokens = idea.split(' ').filter(t => t.length > 2);
  const baseScore = Math.random() * 3 + 5; // Random score between 5-8
  
  return {
    keywords: [
      ...ideaTokens.slice(0, 3),
      industry || 'business',
      'startup',
      'innovation',
      'technology'
    ].filter(Boolean),
    subreddits: ['startups', 'Entrepreneur', 'business', 'SideProject'],
    sentiment_data: [
      { name: 'Enthusiastic', value: 55, color: 'hsl(var(--chart-2))', description: 'Excitement about new solutions' },
      { name: 'Curious/Mixed', value: 30, color: 'hsl(var(--chart-3))', description: 'Questions about implementation' },
      { name: 'Frustrated', value: 15, color: 'hsl(var(--destructive))', description: 'Current market gaps' }
    ],
    pain_points: [
      { title: 'Market Validation', frequency: 85, urgency: 'high', examples: ['Uncertain demand', 'Customer discovery needed'] },
      { title: 'Implementation Challenges', frequency: 65, urgency: 'medium', examples: ['Technical complexity', 'Resource constraints'] }
    ],
    app_ideas: [
      { title: `${ideaTokens[0] || 'Smart'} ${ideaTokens[1] || 'Solution'} Platform`, 
        description: `An innovative approach to ${idea}`, 
        market_validation: 'medium', 
        difficulty: 'medium' }
    ],
    google_trends: [
      { keyword: ideaTokens[0] || 'startup', trend_direction: 'stable', interest_level: Math.round(baseScore * 10), related_queries: ideaTokens.slice(1, 4) }
    ],
    icp: {
      demographics: { age_range: '25-40', gender: 'Mixed', income_level: 'Middle to High', education: 'College Graduate' },
      psychographics: { interests: ideaTokens.slice(0, 3), values: ['Innovation', 'Quality', 'Efficiency'], lifestyle: 'Tech-savvy professional' },
      behavioral: { pain_points: ['Efficiency', 'Cost', 'Complexity'], preferred_channels: ['Online', 'Mobile', 'Social'], buying_behavior: 'Research-driven' }
    },
    problem_statements: [
      { problem: `${targetAudience || 'Users'} need better solutions for ${idea}`,
        impact: 'Significant opportunity for market disruption',
        evidence: ['Customer feedback', 'Market research', 'Competitive analysis'],
        market_size: `Growing ${industry || 'industry'} with increasing demand` }
    ],
    financial_risks: [
      { risk_type: 'Market Adoption', severity: 'medium', description: 'Initial user acquisition challenges', mitigation_strategy: 'MVP testing and iteration' }
    ],
    competitors: [
      { name: 'Established Players', description: 'Current market solutions', strengths: ['Brand recognition', 'User base'], weaknesses: ['Legacy technology', 'Limited innovation'], market_share: 'Dominant but vulnerable', pricing_model: 'Subscription/Freemium' }
    ],
    revenue_models: [
      { model_type: 'Subscription', description: 'Recurring revenue through premium features', pros: ['Predictable income', 'Customer retention'], cons: ['Acquisition costs', 'Churn management'], implementation_difficulty: 'medium', potential_revenue: 'Medium' }
    ],
    market_interest_level: baseScore > 7 ? 'high' : baseScore > 5 ? 'medium' : 'low',
    total_posts_analyzed: Math.floor(Math.random() * 10) + 15, // Random between 15-25
    overall_score: parseFloat(baseScore.toFixed(1)),
    viability_score: parseFloat((baseScore - 0.5).toFixed(1)),
    debug: {
      fallback: 'emergency',
      ms: 120
    }
  };
}

async function performRealAnalysis(input: { idea: string; industry?: string; targetAudience?: string; country: string; platform: string; fundingMethod: string; timeRange: string; }) {
  const started = Date.now();
  console.log('üìã performRealAnalysis started with:', input.idea);
  
  try {
    // 1. Use AI-powered analysis for subreddit discovery
    console.log('ü§ñ Starting AI-powered universal analysis...');
    
    // Import and use AI analysis system
    const { analyzeStartupWithAI } = await import('./ai-powered-analysis');
    const aiAnalysisResult = await analyzeStartupWithAI(input.idea);
    
    console.log(`üéØ AI Analysis: ${aiAnalysisResult.success ? 'AI SUCCESS' : 'Enhanced Fallback Used'}`);
    
    // Enhanced context-aware subreddit selection with market intelligence
    let subreddits: string[] = aiAnalysisResult.subreddits;
  
    // üåü TRUE UNIVERSAL ANALYSIS - Works for ANY startup idea using AI!
    console.log('üåü Using AI-powered universal analysis - handles ALL startup concepts!');
    // Use AI analysis results for intelligent categorization
    const ideaLower = input.idea.toLowerCase();
    const tokens = input.idea.toLowerCase().split(/\s+/).filter((t: string) => t.length > 2);
    
    console.log(`üéØ AI analyzing idea: "${input.idea}"`);
    console.log(`üîç Industry: ${aiAnalysisResult.data.industry || 'General Business'}`);
    console.log(`üéØ Target: ${aiAnalysisResult.data.target_audience || 'General market'}`);
    console.log(`üè™ Business Model: ${aiAnalysisResult.data.business_model || 'TBD'}`);
    console.log(`üìã Selected subreddits: [${subreddits.slice(0, 6).join(', ')}]`);
    console.log(`‚úÖ Analysis method: ${aiAnalysisResult.success ? 'AI-powered' : 'Enhanced keyword fallback'}`);
    
    // For compatibility with existing code, maintain some basic category flags
    // But these are now informed by AI analysis rather than rigid keyword matching
    const isHealth = aiAnalysisResult.data.industry?.toLowerCase().includes('health') || 
                     aiAnalysisResult.data.keywords?.some(k => ['health', 'medical', 'fitness', 'wellness'].includes(k.toLowerCase()));
    const isTech = aiAnalysisResult.data.industry?.toLowerCase().includes('tech') || 
                   aiAnalysisResult.data.keywords?.some(k => ['tech', 'software', 'app', 'platform', 'digital'].includes(k.toLowerCase()));
    const isFinance = aiAnalysisResult.data.industry?.toLowerCase().includes('finance') || 
                      aiAnalysisResult.data.keywords?.some(k => ['finance', 'fintech', 'money', 'investment'].includes(k.toLowerCase()));
    const isEcommerce = aiAnalysisResult.data.business_model?.toLowerCase().includes('marketplace') || 
                        aiAnalysisResult.data.keywords?.some(k => ['ecommerce', 'marketplace', 'retail', 'shop'].includes(k.toLowerCase()));
    
    // Log AI-informed categories
    const aiCategories = [];
    if (isHealth) aiCategories.push('Health/Medical');
    if (isTech) aiCategories.push('Technology');  
    if (isFinance) aiCategories.push('Finance');
    if (isEcommerce) aiCategories.push('E-commerce');
    
    console.log(`ü§ñ AI-informed categories: [${aiCategories.join(', ') || 'General Business'}]`);
    // üöÄ AI-POWERED SUBREDDIT SELECTION - Handles ANY startup idea intelligently
    // Subreddits already selected by AI analysis above
    console.log(`‚úÖ Using ${aiAnalysisResult.success ? 'AI-discovered' : 'enhanced keyword-based'} subreddits`);
    } else if (isSEO) {
      console.log('‚úÖ SEO focused');
      specificSubreddits = ['SEO', 'bigseo', 'TechSEO', 'digitalmarketing', 'marketing', 'webdev'];
    } else if (isPet && (isMarketing || isTech)) {
      console.log('‚úÖ Pet + Social/Tech combo');
      specificSubreddits = ['dogs', 'cats', 'pets', 'DogTraining', 'AskVet', 'petcare'];
    } else if (isMarketing) {
      console.log('‚úÖ Marketing focused');
      specificSubreddits = ['marketing', 'digitalmarketing', 'socialmedia', 'advertising', 'PPC', 'content_marketing'];
    }
    
    // Health & Fitness
    else if (isHealth && isFood) {
      console.log('‚úÖ Health + Food/Nutrition combo');
      specificSubreddits = ['HealthyFood', 'nutrition', 'MealPrepSunday', 'EatCheapAndHealthy', 'loseit', 'fitness'];
    } else if (isHealth || isFitness) {
      console.log('‚úÖ Health/Fitness focused');
      specificSubreddits = ['fitness', 'loseit', 'HealthyFood', 'nutrition', 'bodyweightfitness', 'getmotivated'];
    } else if (isFood) {
      console.log('‚úÖ Food/Cooking focused');
      specificSubreddits = ['Cooking', 'recipes', 'MealPrepSunday', 'EatCheapAndHealthy', 'food', 'nutrition'];
    }
    
    // Professional & Specialized (High Priority - More Specific)
    else if (isLegal) {
      console.log('‚úÖ Legal focused');
      specificSubreddits = ['legaladvice', 'law', 'LawFirm', 'paralegal', 'LegalCareer', 'Ask_Lawyers'];
    } else if (isMedical) {
      console.log('‚úÖ Medical focused');
      specificSubreddits = ['medicine', 'medicalschool', 'nursing', 'healthcare', 'AskDocs', 'medical'];
    } else if (isPet) {
      console.log('‚úÖ Pet focused');
      specificSubreddits = ['dogs', 'cats', 'pets', 'DogTraining', 'AskVet', 'petcare'];
    }
    
    // Education & Productivity (High Priority - Domain Specific)
    else if (isEdu && (isProductivity || isAI)) {
      console.log('‚úÖ Education + Productivity/AI combo');
      specificSubreddits = ['GetStudying', 'studytips', 'college', 'productivity', 'studentsofreddit', 'AskAcademia'];
    } else if (isEdu) {
      console.log('‚úÖ Education focused');
      specificSubreddits = ['education', 'GetStudying', 'studytips', 'Teachers', 'HomeworkHelp', 'AskAcademia'];
    } else if (isProductivity && (isAI || isTech)) {
      console.log('‚úÖ Productivity + Tech combo');
      specificSubreddits = ['productivity', 'GetStudying', 'bujo', 'getmotivated', 'lifehacks', 'studentsofreddit'];
    } else if (isProductivity) {
      console.log('‚úÖ Productivity focused');
      specificSubreddits = ['productivity', 'GetStudying', 'bujo', 'gtd', 'selfimprovement', 'getmotivated'];
    }
    
    // Creative & Design (High Priority - Domain Specific BEFORE generic tech)
    else if (isMusic && (isTech || isAI)) {
      console.log('‚úÖ Music + Tech/AI combo');
      specificSubreddits = ['WeAreTheMusicMakers', 'edmproduction', 'trapproduction', 'makinghiphop', 'musicians', 'streaming'];
    } else if (isMusic) {
      console.log('‚úÖ Music focused');
      specificSubreddits = ['WeAreTheMusicMakers', 'edmproduction', 'trapproduction', 'makinghiphop', 'musicians', 'streaming'];
    } else if (isArt && (isTech || isEcommerce)) {
      console.log('‚úÖ Art + Tech/Marketplace combo');
      specificSubreddits = ['Art', 'learnart', 'ArtCrit', 'painting', 'drawing', 'crafts'];
    } else if (isArt) {
      console.log('‚úÖ Art focused');
      specificSubreddits = ['Art', 'learnart', 'ArtCrit', 'painting', 'drawing', 'crafts'];
    } else if (isDesign) {
      console.log('‚úÖ Design focused');
      specificSubreddits = ['Design', 'userexperience', 'web_design', 'UI_Design', 'graphic_design', 'designfeedback'];
    } else if (isPhoto) {
      console.log('‚úÖ Photography focused');
      specificSubreddits = ['photography', 'photocritique', 'itookapicture', 'streetphotography', 'AskPhotography', 'postprocessing'];
    }
    
    // Technology & AI (Generic - AFTER domain-specific combinations)
    else if (isAI && isTech) {
      console.log('‚úÖ AI + Technology combo');
      specificSubreddits = ['MachineLearning', 'ArtificialIntelligence', 'webdev', 'programming', 'technology', 'SaaS'];
    } else if (isAI) {
      console.log('‚úÖ AI focused');
      specificSubreddits = ['MachineLearning', 'ArtificialIntelligence', 'ChatGPT', 'technology', 'programming', 'singularity'];
    } else if (isTech) {
      console.log('‚úÖ Technology focused');
      specificSubreddits = ['technology', 'webdev', 'programming', 'SaaS', 'mobiledev', 'learnprogramming'];
    }
    
    // Business & Finance
    else if (isCrypto) {
      console.log('‚úÖ Crypto focused');
      specificSubreddits = ['CryptoCurrency', 'Bitcoin', 'ethereum', 'CryptoMarkets', 'defi', 'NFT'];
    } else if (isFin) {
      console.log('‚úÖ Finance focused');
      specificSubreddits = ['personalfinance', 'investing', 'financialindependence', 'SecurityAnalysis', 'StockMarket', 'fintech'];
    } else if (isEcommerce) {
      console.log('‚úÖ E-commerce focused');
      specificSubreddits = ['ecommerce', 'shopify', 'FulfillmentByAmazon', 'dropship', 'amazonprivatelabel', 'OnlineRetail'];
    } else if (isRealEstate) {
      console.log('‚úÖ Real Estate focused');
      specificSubreddits = ['RealEstate', 'realestateinvesting', 'landlord', 'FirstTimeHomeBuyer', 'Mortgages', 'REBubble'];
    }
    
    // Lifestyle & Entertainment
    else if (isGaming) {
      console.log('‚úÖ Gaming focused');
      specificSubreddits = ['gamedev', 'gaming', 'IndieGaming', 'truegaming', 'GameDevelopment', 'Unity3D'];
    } else if (isTravel) {
      console.log('‚úÖ Travel focused');
      specificSubreddits = ['travel', 'solotravel', 'backpacking', 'digitalnomad', 'TravelHacks', 'travel_tips'];
    } else if (isSports) {
      console.log('‚úÖ Sports focused');
      specificSubreddits = ['sports', 'fitness', 'running', 'cycling', 'swimming', 'martialarts'];
    }
    
    // Family & Lifestyle  
    else if (isParenting) {
      console.log('‚úÖ Parenting focused');
      specificSubreddits = ['Parenting', 'NewParents', 'Mommit', 'daddit', 'beyondthebump', 'toddlers'];
    }
    
    // Remaining Professional & Specialized
    else if (isAutomotive) {
      console.log('‚úÖ Automotive focused');
      specificSubreddits = ['cars', 'MechanicAdvice', 'Justrolledintotheshop', 'AutoDetailing', 'whatcarshouldIbuy', 'Cartalk'];
    } else if (isEnvironment) {
      console.log('‚úÖ Environment focused');
      specificSubreddits = ['environment', 'sustainability', 'ZeroWaste', 'climatechange', 'renewable', 'environmental_science'];
    }
    
    // ü§ñ INTELLIGENT FALLBACK - If no specific category matches, analyze the idea text for keywords
    else {
      console.log('ü§ñ No specific category detected, analyzing idea text for relevant communities...');
      
      // üöÄ UNIVERSAL WORD ANALYSIS - Extract ALL meaningful words from ANY idea
      console.log('üîç Extracting all meaningful words from idea for Reddit analysis...');
      
      // Get all meaningful words (remove common words)
      const stopWords = new Set(['a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'will', 'with', 'would', 'i', 'my', 'me', 'we', 'our', 'you', 'your', 'they', 'them', 'their', 'this', 'have', 'had', 'can', 'could', 'should']);
      const meaningfulWords = tokens.filter(word => 
        word.length > 2 && 
        !stopWords.has(word) && 
        !/^\d+$/.test(word) // exclude pure numbers
      );
      
      console.log(`üìù Meaningful words found: [${meaningfulWords.slice(0, 8).join(', ')}${meaningfulWords.length > 8 ? '...' : ''}]`);
      
      // üéØ COMPREHENSIVE KEYWORD-TO-SUBREDDIT MAPPING - Covers 1000+ concepts
      const universalKeywordMap: { [key: string]: string[] } = {
        // Business & Entrepreneurship
        'business': ['Entrepreneur', 'smallbusiness', 'startups'],
        'startup': ['startups', 'Entrepreneur', 'business'],
        'company': ['Entrepreneur', 'business', 'startups'],
        'service': ['Entrepreneur', 'smallbusiness', 'business'],
        'product': ['Entrepreneur', 'product_design', 'startups'],
        'subscription': ['SaaS', 'Entrepreneur', 'startups'],
        'saas': ['SaaS', 'Entrepreneur', 'webdev'],
        
        // Technology & Development
        'app': ['webdev', 'mobiledev', 'technology'],
        'software': ['programming', 'webdev', 'technology'],
        'website': ['webdev', 'web_design', 'technology'],
        'platform': ['webdev', 'technology', 'SaaS'],
        'api': ['webdev', 'programming', 'technology'],
        'database': ['database', 'programming', 'webdev'],
        'cloud': ['aws', 'webdev', 'technology'],
        'mobile': ['mobiledev', 'webdev', 'technology'],
        'web': ['webdev', 'web_design', 'technology'],
        'tech': ['technology', 'webdev', 'programming'],
        'digital': ['technology', 'webdev', 'digital_marketing'],
        
        // AI & Machine Learning
        'ai': ['MachineLearning', 'artificial', 'technology'],
        'artificial': ['MachineLearning', 'artificial', 'technology'],
        'machine': ['MachineLearning', 'datascience', 'technology'],
        'learning': ['MachineLearning', 'GetStudying', 'education'],
        'algorithm': ['MachineLearning', 'programming', 'compsci'],
        'chatbot': ['MachineLearning', 'artificial', 'technology'],
        'automation': ['MachineLearning', 'productivity', 'technology'],
        
        // E-commerce & Retail
        'ecommerce': ['ecommerce', 'Entrepreneur', 'shopify'],
        'shop': ['ecommerce', 'smallbusiness', 'Entrepreneur'],
        'store': ['ecommerce', 'smallbusiness', 'retail'],
        'marketplace': ['ecommerce', 'Entrepreneur', 'startups'],
        'selling': ['ecommerce', 'Entrepreneur', 'smallbusiness'],
        'amazon': ['FulfillmentByAmazon', 'ecommerce', 'amazonprivatelabel'],
        'shopify': ['shopify', 'ecommerce', 'Entrepreneur'],
        'dropship': ['dropship', 'ecommerce', 'Entrepreneur'],
        'retail': ['retail', 'ecommerce', 'smallbusiness'],
        
        // Health & Wellness
        'health': ['Health', 'fitness', 'wellness'],
        'medical': ['medicine', 'healthcare', 'AskDocs'],
        'fitness': ['fitness', 'loseit', 'bodyweightfitness'],
        'nutrition': ['nutrition', 'HealthyFood', 'fitness'],
        'wellness': ['wellness', 'fitness', 'mindfulness'],
        'mental': ['mentalhealth', 'anxiety', 'depression'],
        'therapy': ['therapy', 'mentalhealth', 'psychology'],
        'meditation': ['Meditation', 'mindfulness', 'buddhism'],
        'doctor': ['AskDocs', 'medicine', 'healthcare'],
        'hospital': ['medicine', 'nursing', 'healthcare'],
        
        // Finance & Investment
        'finance': ['personalfinance', 'investing', 'financialindependence'],
        'money': ['personalfinance', 'investing', 'finance'],
        'investment': ['investing', 'SecurityAnalysis', 'StockMarket'],
        'trading': ['investing', 'StockMarket', 'SecurityAnalysis'],
        'crypto': ['CryptoCurrency', 'Bitcoin', 'ethereum'],
        'bitcoin': ['Bitcoin', 'CryptoCurrency', 'BitcoinBeginners'],
        'blockchain': ['CryptoCurrency', 'ethereum', 'Bitcoin'],
        'bank': ['banking', 'personalfinance', 'finance'],
        'budget': ['personalfinance', 'budget', 'finance'],
        
        // Education & Learning
        'education': ['education', 'Teachers', 'GetStudying'],
        'student': ['GetStudying', 'college', 'studentsofreddit'],
        'school': ['education', 'Teachers', 'GetStudying'],
        'university': ['college', 'AskAcademia', 'education'],
        'course': ['GetStudying', 'education', 'OnlineEducation'],
        'tutorial': ['tutorials', 'GetStudying', 'education'],
        'study': ['GetStudying', 'studytips', 'college'],
        'homework': ['HomeworkHelp', 'GetStudying', 'education'],
        'notes': ['GetStudying', 'studytips', 'productivity'],
        
        // Creative & Arts
        'art': ['Art', 'learnart', 'ArtCrit'],
        'design': ['Design', 'graphic_design', 'web_design'],
        'creative': ['creativity', 'Art', 'Design'],
        'music': ['WeAreTheMusicMakers', 'edmproduction', 'musicians'],
        'photo': ['photography', 'photocritique', 'itookapicture'],
        'video': ['videography', 'VideoEditing', 'filmmakers'],
        'writing': ['writing', 'WritingPrompts', 'writers'],
        'painting': ['painting', 'Art', 'learnart'],
        'drawing': ['drawing', 'learnart', 'Art'],
        
        // Gaming & Entertainment
        'game': ['gamedev', 'gaming', 'IndieGaming'],
        'gaming': ['gaming', 'gamedev', 'pcgaming'],
        'stream': ['streaming', 'Twitch', 'content_creation'],
        'esports': ['esports', 'gaming', 'CompetitiveHS'],
        'twitch': ['Twitch', 'streaming', 'content_creation'],
        'youtube': ['youtube', 'NewTubers', 'content_creation'],
        
        // Social & Communication
        'social': ['socialmedia', 'marketing', 'community'],
        'community': ['community', 'socialmedia', 'ModSupport'],
        'chat': ['chat', 'communication', 'technology'],
        'messaging': ['messaging', 'communication', 'technology'],
        'dating': ['dating', 'relationships', 'datingoverthirty'],
        'relationship': ['relationships', 'dating', 'marriage'],
        
        // Food & Cooking
        'food': ['Cooking', 'food', 'recipes'],
        'cooking': ['Cooking', 'recipes', 'MealPrepSunday'],
        'recipe': ['recipes', 'Cooking', 'MealPrepSunday'],
        'restaurant': ['KitchenConfidential', 'Cooking', 'food'],
        'kitchen': ['Cooking', 'KitchenConfidential', 'food'],
        'delivery': ['couriersofreddit', 'doordash_drivers', 'food'],
        
        // Travel & Transportation
        'travel': ['travel', 'solotravel', 'backpacking'],
        'trip': ['travel', 'solotravel', 'digitalnomad'],
        'hotel': ['travel', 'hospitality', 'hotels'],
        'flight': ['travel', 'flights', 'solotravel'],
        'car': ['cars', 'whatcarshouldIbuy', 'MechanicAdvice'],
        'transportation': ['transportation', 'transit', 'cars'],
        
        // Real Estate & Housing
        'real': ['RealEstate', 'realestateinvesting', 'FirstTimeHomeBuyer'],
        'estate': ['RealEstate', 'realestateinvesting', 'landlord'],
        'house': ['RealEstate', 'HomeImprovement', 'FirstTimeHomeBuyer'],
        'apartment': ['RealEstate', 'landlord', 'tenant'],
        'rent': ['RealEstate', 'landlord', 'tenant'],
        'property': ['RealEstate', 'realestateinvesting', 'landlord'],
        
        // Legal & Professional
        'legal': ['legaladvice', 'law', 'Ask_Lawyers'],
        'law': ['law', 'legaladvice', 'LawSchool'],
        'lawyer': ['Ask_Lawyers', 'law', 'legaladvice'],
        'contract': ['legaladvice', 'law', 'Entrepreneur'],
        
        // Sports & Fitness
        'sport': ['sports', 'fitness', 'running'],
        'workout': ['fitness', 'bodyweightfitness', 'Fitness'],
        'gym': ['fitness', 'bodybuilding', 'weightroom'],
        'running': ['running', 'fitness', 'C25K'],
        'cycling': ['cycling', 'bicycling', 'fitness'],
        
        // Pets & Animals
        'pet': ['pets', 'dogs', 'cats'],
        'dog': ['dogs', 'DogTraining', 'puppy101'],
        'cat': ['cats', 'CatAdvice', 'pets'],
        'animal': ['animals', 'pets', 'NatureIsFuckingLit'],
        
        // Parenting & Family
        'parent': ['Parenting', 'daddit', 'Mommit'],
        'baby': ['beyondthebump', 'NewParents', 'Parenting'],
        'child': ['Parenting', 'Mommit', 'daddit'],
        'family': ['family', 'Parenting', 'relationships'],
        
        // Environment & Sustainability
        'environment': ['environment', 'sustainability', 'climatechange'],
        'green': ['sustainability', 'ZeroWaste', 'environment'],
        'sustainable': ['sustainability', 'ZeroWaste', 'environment'],
        'climate': ['climatechange', 'environment', 'sustainability'],
        'renewable': ['renewable', 'environment', 'sustainability'],
        
        // Productivity & Organization
        'productivity': ['productivity', 'getmotivated', 'selfimprovement'],
        'organize': ['organization', 'productivity', 'lifehacks'],
        'task': ['productivity', 'gtd', 'organization'],
        'calendar': ['productivity', 'organization', 'lifehacks'],
        'planner': ['bujo', 'productivity', 'organization'],
        
        // Marketing & Advertising
        'marketing': ['marketing', 'digitalmarketing', 'advertising'],
        'advertising': ['advertising', 'marketing', 'PPC'],
        'brand': ['marketing', 'branding', 'graphic_design'],
        'seo': ['SEO', 'digitalmarketing', 'marketing'],
        
        // Miscellaneous but important
        'book': ['books', 'booksuggestions', 'reading'],
        'news': ['news', 'worldnews', 'politics'],
        'weather': ['weather', 'meteorology', 'science'],
        'security': ['netsec', 'cybersecurity', 'security'],
        'privacy': ['privacy', 'security', 'technology'],
        'data': ['datascience', 'analytics', 'MachineLearning'],
        'analytics': ['analytics', 'datascience', 'webdev']
      };
      
      // Find ALL matching subreddits from meaningful words
      let discoveredSubreddits: string[] = [];
      let matchedWords: string[] = [];
      
      for (const word of meaningfulWords) {
        if (universalKeywordMap[word]) {
          console.log(`üéØ Found "${word}" ‚Üí adding: [${universalKeywordMap[word].slice(0, 2).join(', ')}...]`);
          discoveredSubreddits = discoveredSubreddits.concat(universalKeywordMap[word]);
          matchedWords.push(word);
        }
      }
      
      console.log(`‚úÖ Matched ${matchedWords.length} words: [${matchedWords.join(', ')}]`);
      
      if (discoveredSubreddits.length > 0) {
        // Remove duplicates and prioritize by frequency
        const subredditCounts = discoveredSubreddits.reduce((acc: {[key: string]: number}, sub: string) => {
          acc[sub] = (acc[sub] || 0) + 1;
          return acc;
        }, {});
        
        // Sort by frequency (most mentioned first) and take top 6
        specificSubreddits = Object.entries(subredditCounts)
          .sort(([,a], [,b]) => b - a)
          .slice(0, 6)
          .map(([sub]) => sub);
          
        console.log(`‚úÖ Universal analysis found ${specificSubreddits.length} relevant communities:`, specificSubreddits);
      } else {
        // üîÑ BACKUP ANALYSIS - Try partial word matching for compound concepts
        console.log('üîç No exact matches found, trying partial word analysis...');
        
        const partialMatches: string[] = [];
        for (const word of meaningfulWords) {
          // Check if word contains any known keywords
          for (const [keyword, subs] of Object.entries(universalKeywordMap)) {
            if (word.includes(keyword) || keyword.includes(word)) {
              console.log(`üéØ Partial match: "${word}" contains "${keyword}"`);
              partialMatches.push(...subs.slice(0, 2));
              break;
            }
          }
        }
        
        if (partialMatches.length > 0) {
          specificSubreddits = Array.from(new Set(partialMatches)).slice(0, 6);
          console.log('‚úÖ Partial match communities:', specificSubreddits);
        } else {
          // üåê ULTIMATE FALLBACK - Smart general communities based on idea characteristics
          console.log('üåê Using intelligent general communities based on idea pattern...');
          
          if (ideaLower.includes('problem') || ideaLower.includes('solution') || ideaLower.includes('help')) {
            specificSubreddits = ['AskReddit', 'NoStupidQuestions', 'explainlikeimfive', 'Entrepreneur', 'startups'];
          } else if (ideaLower.includes('make') || ideaLower.includes('build') || ideaLower.includes('create')) {
            specificSubreddits = ['DIY', 'somethingimade', 'Entrepreneur', 'startups', 'technology'];
          } else if (ideaLower.includes('sell') || ideaLower.includes('buy') || ideaLower.includes('market')) {
            specificSubreddits = ['Entrepreneur', 'smallbusiness', 'startups', 'ecommerce', 'marketing'];
          } else {
            // Final diverse fallback
            specificSubreddits = ['AskReddit', 'Entrepreneur', 'startups', 'technology', 'business', 'smallbusiness'];
          }
          
          console.log('‚úÖ Intelligent general communities selected:', specificSubreddits);
        }
      }
    }
    
    // AI has already selected the best subreddits - no need for additional logic
    console.log('‚úÖ Final AI-selected subreddits:', subreddits);
    
    // Ensure we have at least some subreddits (safety check)
    if (subreddits.length === 0) {
      console.warn('‚ö†Ô∏è AI analysis failed, using intelligent fallback');
      subreddits = ['Entrepreneur', 'startups', 'business', 'technology'];
    }

    // 2. Fetch top posts using Reddit OAuth API first, then fallback to public JSON
    let fetchedPosts: RawRedditPost[] = [];
    let usedOAuth = false;
    
    // Try Reddit OAuth first if credentials are available
    const hasRedditCreds = process.env.REDDIT_CLIENT_ID && process.env.REDDIT_CLIENT_SECRET;
    console.log('üî• Reddit OAuth check - has creds:', hasRedditCreds, 'client_id length:', process.env.REDDIT_CLIENT_ID?.length || 0, 'secret length:', process.env.REDDIT_CLIENT_SECRET?.length || 0);
    
    if (hasRedditCreds) {
      try {
        console.log('üîë Attempting Reddit OAuth authentication...');
        const token = await getRedditOAuthToken(
          process.env.REDDIT_CLIENT_ID!,
          process.env.REDDIT_CLIENT_SECRET!
        );
        console.log('üîë Reddit OAuth token result:', token ? 'SUCCESS' : 'FAILED');
        
        if (token) {
          console.log('‚úÖ Reddit OAuth token obtained, fetching posts...');
          for (const sub of subreddits) {
            if (fetchedPosts.length >= 12) break;
            console.log(`üîç OAuth: Trying r/${sub}`);
            const posts = await fetchRedditPosts(sub, token, 8);
            posts.forEach((p: any) => {
              if (fetchedPosts.length < 12) fetchedPosts.push({
                title: String(p.title).trim(),
                selftext: String(p.selftext || '').trim(),
                score: Math.max(1, parseInt(p.score) || 1),
                num_comments: Math.max(0, parseInt(p.num_comments) || 0),
                created_utc: p.created_utc || Math.floor(Date.now()/1000),
                permalink: p.permalink || '',
                subreddit: p.subreddit || sub,
                source: 'reddit'
              });
            });
          }
          usedOAuth = true;
          console.log(`‚úÖ OAuth: Fetched ${fetchedPosts.length} posts via Reddit API`);
        }
      } catch (oauthErr) {
        console.warn('‚ùå Reddit OAuth failed:', (oauthErr as Error).message);
        console.warn('‚ùå OAuth Error Stack:', (oauthErr as Error).stack);
      }
    } else {
      console.log('‚ö†Ô∏è Reddit OAuth credentials not found, will use public endpoint');
    }
    
    // Fallback to public JSON endpoint if OAuth failed or no credentials
    if (!usedOAuth || fetchedPosts.length === 0) {
      console.log('üåê Falling back to public Reddit JSON endpoints...');
      for (const sub of subreddits) {
        if (fetchedPosts.length >= 12) break;
        const url = `https://www.reddit.com/r/${sub}/top.json?limit=25&t=week`;
        console.log(`üîç Public: Trying r/${sub}`);
        try {
          const response = await fetch(url, {
            headers: { 
              'User-Agent': 'Mozilla/5.0 (compatible; IdeaVoyage/1.0; +https://ideavoyage.vercel.app)',
              'Accept': 'application/json'
            },
            signal: AbortSignal.timeout(8000) as unknown as AbortSignal
          });
          if (response.ok) {
            const data = await response.json() as any;
            const posts = (data?.data?.children || []).map((c: any) => c.data).filter((p: any) => p.title).slice(0, 25);
            posts.forEach((p: any) => {
              if (fetchedPosts.length < 12) {
                const title = String(p.title).trim();
                const selftext = String(p.selftext || '').trim();
                const score = Math.max(1, parseInt(p.score) || 1);
                const num_comments = Math.max(0, parseInt(p.num_comments) || 0);
                
                // Enhanced data extraction for better analysis
                const post: RawRedditPost = {
                  title,
                  selftext,
                  score,
                  num_comments,
                  created_utc: p.created_utc || Math.floor(Date.now()/1000),
                  permalink: p.permalink || '',
                  subreddit: p.subreddit || sub,
                  source: 'reddit'
                };

                // Add metadata for enhanced analysis
                (post as any).engagement_ratio = score > 0 ? num_comments / score : 0;
                (post as any).content_length = selftext.length;
                (post as any).post_age_days = Math.floor((Date.now() / 1000 - (p.created_utc || 0)) / 86400);
                (post as any).signals = {
                  is_problem_focused: /\b(problem|issue|frustrat|difficult|annoying|hate|struggle)\b/i.test(title + ' ' + selftext),
                  is_solution_seeking: /\b(recommend|suggest|help|solution|alternative|tool|app|software)\b/i.test(title + ' ' + selftext),
                  is_pain_point: /\b(pain|headache|nightmare|terrible|awful|worst)\b/i.test(title + ' ' + selftext),
                  mentions_cost: /\b(price|cost|expensive|cheap|budget|money|pay|fee)\b/i.test(title + ' ' + selftext),
                  mentions_competitors: /\b(vs|versus|alternative|instead|better than)\b/i.test(title + ' ' + selftext)
                };

                fetchedPosts.push(post);
              }
            });
            console.log(`‚úÖ Public: Total real posts so far: ${fetchedPosts.length}`);
          } else {
            console.warn(`‚ö†Ô∏è r/${sub} returned ${response.status}`);
          }
        } catch (err) {
          console.warn(`‚ùå r/${sub} fetch error: ${(err as Error).message}`);
        }
      }
    }
  
  // Log what we actually fetched with detailed information
  console.log(`üìä Reddit fetch results: ${fetchedPosts.length} posts from ${subreddits.length} subreddits`);
  fetchedPosts.forEach((post, i) => {
    console.log(`  Post ${i+1}: "${post.title.substring(0, 50)}..." - Score: ${post.score}, Comments: ${post.num_comments} (r/${post.subreddit})`);
  });
  
  // Always ensure we have enough data for analysis by adding synthetic posts when needed
  console.log(`üìä Real posts fetched: ${fetchedPosts.length}, adding synthetic posts for comprehensive analysis...`);
  const fallbackSub = subreddits[0] || 'startups';
  const syntheticPosts = generateRealisticSyntheticPosts(input.idea, input.industry || '', fallbackSub);
  
  // Add synthetic posts to ensure we have at least 8-12 posts for analysis
  const targetPostCount = Math.max(12, fetchedPosts.length + 6);
  const postsToAdd = Math.min(syntheticPosts.length, targetPostCount - fetchedPosts.length);
  fetchedPosts.push(...syntheticPosts.slice(0, postsToAdd));
  console.log(`‚úÖ Added ${postsToAdd} synthetic posts (now ${fetchedPosts.length} total for analysis)`);
  
  // Mark this as using mixed data for transparency
  const hasMixedData = fetchedPosts.some(p => p.source === 'reddit') && fetchedPosts.some(p => p.source === 'synthetic');
  
  // If we still have very few posts, try a final aggressive approach
  if (fetchedPosts.length < 5) {
    console.log(`‚ö†Ô∏è Still low post count (${fetchedPosts.length}), trying final aggressive fetch...`);
    
    // Try some general subreddits that usually work
    const backupSubs = ['AskReddit', 'technology', 'business', 'SideProject'];
    
    for (const sub of backupSubs) {
      if (fetchedPosts.length > 15) break;
      
      try {
        const url = `https://www.reddit.com/r/${sub}/rising.json?limit=25`;
        const response = await fetch(url, {
          headers: { 
            'User-Agent': 'Mozilla/5.0 (compatible; RedditReader/1.0)',
            'Accept': 'application/json'
          },
          signal: AbortSignal.timeout(3000) as unknown as AbortSignal
        });
        
        if (response.ok) {
          const data = await response.json() as any;
          const posts = (data?.data?.children || [])
            .map((c: any) => c.data)
            .filter((p: any) => p && p.title && p.title.length > 15)
            .slice(0, 25);
          
          posts.forEach((p: any) => {
            fetchedPosts.push({
              title: String(p.title).trim(),
              selftext: String(p.selftext || '').trim(),
              score: Math.max(1, parseInt(p.score) || Math.floor(Math.random() * 50) + 10),
              num_comments: Math.max(0, parseInt(p.num_comments) || Math.floor(Math.random() * 20)),
              created_utc: p.created_utc || (Math.floor(Date.now()/1000) - Math.floor(Math.random() * 86400)),
              permalink: p.permalink || `/r/${sub}/comments/${Date.now()}`,
              subreddit: p.subreddit || sub,
              source: 'reddit'
            });
          });
          
          console.log(`‚úÖ Backup fetch got ${posts.length} posts from r/${sub}`);
        }
      } catch (e) {
        console.log(`‚ùå Backup fetch failed for r/${sub}`);
      }
    }
  }
  
  console.log(`üìà Final post count: ${fetchedPosts.length} posts for analysis`)

  // 3. Advanced keyword extraction focused on real Reddit content
  console.log(`üîç Analyzing ${fetchedPosts.length} posts for keywords...`);
  
  // Create rich text corpus from real posts
  const titleCorpus = fetchedPosts.map(p => p.title).join(' ').toLowerCase();
  const contentCorpus = fetchedPosts.map(p => p.selftext).join(' ').toLowerCase();
  const fullCorpus = `${titleCorpus} ${contentCorpus} ${input.idea.toLowerCase()}`;
  
  // Enhanced stopwords list
  const stopWords = new Set(['with', 'that', 'have', 'this', 'about', 'from', 'https', 'reddit', 'they', 
    'their', 'will', 'your', 'just', 'what', 'when', 'where', 'which', 'who', 'whom', 'these',
    'those', 'then', 'than', 'some', 'such', 'also', 'here', 'there', 'into', 'over', 'under',
    'should', 'would', 'could', 'been', 'were', 'comment', 'post', 'like', 'want', 'need', 
    'make', 'good', 'best', 'know', 'think', 'time', 'help', 'work', 'find', 'user', 'people']);
  
  // Extract and count meaningful terms
  const termFreq: Record<string, number> = {};
  const words = fullCorpus.split(/[^a-z0-9]+/).filter(word => 
    word.length >= 4 && 
    word.length <= 20 && 
    !stopWords.has(word) &&
    !/^\d+$/.test(word) && // no pure numbers
    /[a-z]/.test(word) // must contain letters
  );
  
  words.forEach(word => {
    termFreq[word] = (termFreq[word] || 0) + 1;
  });
  
  // Get high-value keywords - prefer terms that appear multiple times
  let extractedKeywords = Object.entries(termFreq)
    .filter(([word, count]) => count >= Math.max(1, Math.floor(fetchedPosts.length / 10)))
    .sort((a, b) => b[1] - a[1])
    .slice(0, 12)
    .map(([word]) => word);
  
  // Add idea-specific terms to ensure relevance
  const ideaTerms = input.idea.toLowerCase()
    .split(/[^a-z0-9]+/)
    .filter(word => word.length > 3 && !stopWords.has(word))
    .slice(0, 4);
  
  // Industry-specific enrichment
  const domainKeywords: string[] = [];
  if (isAI) domainKeywords.push('artificial', 'intelligence', 'machine', 'learning', 'algorithm');
  if (isFitness) domainKeywords.push('fitness', 'health', 'exercise', 'workout', 'nutrition');
  if (isEdu) domainKeywords.push('education', 'learning', 'course', 'teaching', 'student');
  if (isFin) domainKeywords.push('finance', 'investment', 'money', 'financial', 'trading');
  
  // Combine all keyword sources intelligently
  const allKeywordCandidates = [
    ...extractedKeywords,
    ...ideaTerms, 
    ...domainKeywords.slice(0, 3)
  ];
  
  // Deduplicate and prioritize (keep order which prioritizes extracted > idea > domain)
  const finalKeywords = Array.from(new Set(allKeywordCandidates)).slice(0, 10);
  
  console.log(`üìù Extracted keywords: ${finalKeywords.join(', ')}`);
  const frequentTerms = finalKeywords;

  // Heuristic pain point candidates
  const painCandidates: Record<string, {count:number; examples:Set<string>}> = {};
  const painSignals = ['problem','issue','struggle','hard','difficult','confusing','annoying','need','pain','frustrated'];
  fetchedPosts.slice(0,40).forEach(p => {
    const lower = (p.title + ' ' + (p.selftext||'')).toLowerCase();
    if (painSignals.some(sig => lower.includes(sig))) {
      // pick a term present
      const key = painSignals.find(sig => lower.includes(sig)) || 'problem';
      if (!painCandidates[key]) painCandidates[key] = {count:0, examples:new Set()};
      painCandidates[key].count++;
      if (painCandidates[key].examples.size < 3) painCandidates[key].examples.add(p.title.substring(0,120));
    }
  });
  const pain_points_heuristic = Object.entries(painCandidates).map(([k,v]) => ({
    title: k.charAt(0).toUpperCase()+k.slice(1),
    frequency: clamp(v.count*15, 10, 95),
    urgency: v.count > 5 ? 'high' : v.count > 2 ? 'medium' : 'low',
    examples: Array.from(v.examples)
  })).slice(0,10);

  // 4. AI enrichment - PERPLEXITY ONLY (fast, reliable, comprehensive)
  let enriched: Partial<ReturnType<typeof buildBaseResponse>> | null = null;
  const hasPerplexityKey = !!process.env.PERPLEXITY_API_KEY?.trim();
  console.log('üî• Using Perplexity for ALL AI analysis - has key:', hasPerplexityKey, 'key length:', process.env.PERPLEXITY_API_KEY?.length || 0);
  
  // Try Perplexity first (faster and more reliable)
  if (hasPerplexityKey) {
    console.log('üî• Using Perplexity as primary AI provider...');
    try {
      const realPosts = fetchedPosts.filter(p => p.source === 'reddit');
      const samplePosts = realPosts.length > 0 
        ? realPosts.slice(0, 20).map(p => `- "${p.title}" (${p.score} upvotes, ${p.num_comments} comments on r/${p.subreddit})`).join('\n')
        : 'No real Reddit data available - using market analysis approach';
      
      const dataContext = realPosts.length > 0 
        ? `Based on ${realPosts.length} real Reddit discussions:\n${samplePosts}\n\n`
        : 'No real Reddit data available. Provide market-validated insights based on industry knowledge:\n\n';
      
      const system = `You are a senior market research analyst with 10+ years experience analyzing Reddit communities and startup validation. You specialize in extracting deep user insights from real discussions and combining them with market intelligence to provide actionable startup advice.`;

      // Analyze actual Reddit post content to extract real user insights
      const redditAnalysis = realPosts.length > 0 
        ? realPosts.slice(0, 20).map((p, i) => {
            const content = p.selftext ? p.selftext.substring(0, 300) : '';
            return `POST ${i+1} [r/${p.subreddit}]:
Title: "${p.title}"
Content: "${content}${content.length >= 300 ? '...' : ''}"
Engagement: ${p.score} upvotes, ${p.num_comments} comments
User Signals: ${p.title.toLowerCase().includes('problem') || p.title.toLowerCase().includes('issue') ? 'pain_point' : 
               p.title.toLowerCase().includes('solution') || p.title.toLowerCase().includes('app') ? 'solution_seeking' :
               p.title.toLowerCase().includes('recommendation') || p.title.toLowerCase().includes('help') ? 'advice_seeking' : 'discussion'}`;
          }).join('\n\n')
        : 'No real Reddit discussions available - analyze based on market knowledge';

      const userPrompt = `STARTUP IDEA ANALYSIS:
üí° IDEA: "${input.idea}"
üìä INDUSTRY: ${input.industry || 'Technology'}
üë• TARGET: ${input.targetAudience || 'General users'}
üéØ COMMUNITIES: ${subreddits.join(', ')}

REAL REDDIT DISCUSSIONS TO ANALYZE:
${redditAnalysis}

COMPREHENSIVE ANALYSIS REQUIRED:
Analyze the above Reddit discussions to extract real user insights, pain points, and market opportunities. Combine this with your market knowledge to provide detailed startup validation.

Return ONLY valid JSON:
{
  "keywords": ["exact_terms_users_actually_use", "pain_point_phrases_from_posts", "solution_terms_mentioned", "industry_jargon_detected", "market_opportunity_keywords"],
  "pain_points": [
    {
      "title": "Exact problem from Reddit discussions",
      "frequency": 85,
      "urgency": "high",
      "examples": ["Direct quotes from Reddit posts", "Specific user complaints found"],
      "current_solutions": ["How users currently solve this", "Workarounds mentioned in posts"],
      "market_evidence": "Evidence from Reddit discussions showing this pain point"
    }
  ],
  "app_ideas": [
    {
      "title": "Solution addressing Reddit-identified problems",
      "description": "Detailed solution based on actual user needs found in discussions",
      "market_validation": "high",
      "difficulty": "medium",
      "reddit_evidence": "Why Reddit discussions validate this idea"
    }
  ],
  "competitors": [
    {
      "name": "Actual competitor mentioned in Reddit or market research",
      "strengths": ["Real advantages mentioned by users"],
      "weaknesses": ["Gaps identified in Reddit discussions"],
      "market_share": "Research-based estimate",
      "user_sentiment": "What Reddit users actually say about them"
    }
  ],
  "revenue_models": [
    {
      "model_type": "Model validated by user behavior in Reddit",
      "description": "Revenue approach based on what users actually pay for",
      "pros": ["Advantages based on user preferences"],
      "cons": ["Challenges identified from user discussions"],
      "market_evidence": "Reddit evidence supporting this model"
    }
  ],
  "market_insights": {
    "reddit_community_size": "Size of communities discussing this",
    "user_demographics": "Profile of users from Reddit analysis",
    "adoption_barriers": ["Real obstacles mentioned by users"],
    "market_timing": "Market readiness based on discussion trends"
  }
}`;

      console.log('üî• Starting Perplexity API call...');
      console.log('üî• Analyzing', realPosts.length, 'real Reddit posts with Perplexity');
      console.log('üî• Prompt length:', userPrompt.length, 'characters');
      const perplexityResponse = await fetch('https://api.perplexity.ai/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'sonar',
          messages: [
            { role: 'system', content: system },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.5,
          max_tokens: 2000,
        })
      });
      
      if (perplexityResponse.ok) {
        const completion = await perplexityResponse.json();
        const raw = completion.choices[0]?.message?.content || '{}';
        console.log('‚úÖ Perplexity response received, length:', raw.length);
        console.log('üîç First 200 chars:', raw.substring(0, 200));
        
        // Try to parse JSON
        try {
          enriched = JSON.parse(raw);
          console.log('‚úÖ Perplexity enrichment successful!');
          console.log('üîç Pain points found:', enriched?.pain_points?.length || 0);
          console.log('üîç Keywords found:', enriched?.keywords?.length || 0);
        } catch (parseErr) {
          console.log('‚ö†Ô∏è JSON parse failed, trying markdown extraction...');
          // Try to extract JSON from markdown
          const jsonMatch = raw.match(/```json\s*([\s\S]*?)\s*```/) || raw.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            try {
              enriched = JSON.parse(jsonMatch[1] || jsonMatch[0]);
              console.log('‚úÖ Perplexity JSON extracted from markdown');
              console.log('üîç Pain points found:', enriched?.pain_points?.length || 0);
            } catch (extractErr) {
              console.warn('‚ùå Even markdown extraction failed:', (extractErr as Error).message);
              console.warn('üîç Raw response sample:', raw.substring(0, 500));
            }
          } else {
            console.warn('‚ö†Ô∏è Could not find any JSON in Perplexity response');
            console.warn('üîç Raw response sample:', raw.substring(0, 500));
          }
        }
      } else {
        const errorText = await perplexityResponse.text();
        console.warn('‚ùå Perplexity API error:', perplexityResponse.status, perplexityResponse.statusText);
        console.warn('‚ùå Error details:', errorText.substring(0, 300));
      }
    } catch (perplexityErr) {
      console.error('‚ùå Perplexity failed:', (perplexityErr as Error).message);
    }
  }
  
  // Pure Perplexity approach - no fallbacks needed (Perplexity is faster and more reliable)
  if (!enriched) {
    console.log('üåü Perplexity unavailable - using comprehensive heuristic analysis');
  }

  // 5. Build response
  // Separate real vs synthetic posts for transparency & scoring
  const realPostsOnly = fetchedPosts.filter(p => p.source !== 'synthetic');

  // Debug what's being passed to buildBaseResponse
  console.log('üèóÔ∏è Building response with:');
  console.log('üèóÔ∏è Using enriched keywords:', enriched?.keywords ? 'YES' : 'NO (fallback to heuristic)');
  console.log('üèóÔ∏è Using enriched subreddits:', enriched?.subreddits ? 'YES' : 'NO (fallback to detected)');
  console.log('üèóÔ∏è Using enriched pain_points:', enriched?.pain_points ? 'YES' : 'NO (fallback to heuristic)');
  console.log('üèóÔ∏è Detected subreddits fallback:', subreddits?.slice(0,3));

  const response = buildBaseResponse({
    idea: input.idea,
    industry: input.industry,
    targetAudience: input.targetAudience,
    isAI, isFitness, tokens,
    keywords: enriched?.keywords || frequentTerms.slice(0,7),
    subreddits: enriched?.subreddits || subreddits,
    pain_points: (enriched?.pain_points as any) || (pain_points_heuristic.length ? pain_points_heuristic : [
      { title: 'Validation Gap', frequency: 55, urgency: 'medium', examples: ['Need better evidence for idea viability'] }
    ]),
    app_ideas: (enriched?.app_ideas as any) || [
      { title: `Smart ${tokens[0]||'Market'} Analyzer`, description: 'Tool that synthesizes community signals into actionable validation metrics', market_validation: 'medium', difficulty: isAI ? 'hard' : 'medium' }
    ],
    competitors: (enriched?.competitors as any) || [
      { name: 'Generic Tools', description: 'Existing broad solutions lacking niche focus', strengths: ['Brand'], weaknesses: ['Low specialization'], market_share: 'Fragmented', pricing_model: 'Subscription' }
    ],
    revenue_models: (enriched?.revenue_models as any) || [
      { model_type: 'Subscription', description: 'Monthly access to analysis dashboard', pros: ['Predictable revenue'], cons: ['Churn risk'], implementation_difficulty: 'medium', potential_revenue: 'Medium' }
    ],
    fetchedPosts: realPostsOnly.length ? realPostsOnly : (
      // Use OpenAI-generated posts if available, otherwise fallback to synthetic
      enriched && (enriched as any).realistic_posts 
        ? (enriched as any).realistic_posts.map((p: any, i: number) => ({
            title: p.title || `AI-generated post ${i+1}`,
            selftext: '',
            score: p.score || Math.floor(Math.random() * 50) + 10,
            num_comments: p.num_comments || Math.floor(Math.random() * 20) + 2,
            created_utc: Math.floor(Date.now() / 1000) - Math.floor(Math.random() * 86400),
            permalink: `/r/startups/comments/ai_generated_${i}/`,
            subreddit: 'startups',
            source: 'ai_generated'
          }))
        : fetchedPosts
    )
  });

  const durationMs = Date.now() - started;
  const aiGeneratedPosts = enriched && (enriched as any).realistic_posts ? (enriched as any).realistic_posts : [];
  const finalPostsUsed = realPostsOnly.length ? realPostsOnly : (aiGeneratedPosts.length ? aiGeneratedPosts : fetchedPosts);
  
  (response as any).debug = { 
    postsFetched: fetchedPosts.length,
    realPosts: realPostsOnly.length,
    syntheticPosts: fetchedPosts.filter(p => p.source === 'synthetic').length,
    aiGeneratedPosts: aiGeneratedPosts.length,
    sampleTitles: finalPostsUsed.slice(0,5).map((p: any) => p.title || String(p)),
    enriched: !!enriched, 
    perplexity_available: hasPerplexityKey,
    reddit_oauth_used: usedOAuth,
    reddit_creds_available: hasRedditCreds,
    mode: enriched && aiGeneratedPosts.length > 0 ? 'perplexity_enhanced_with_posts' : enriched ? 'perplexity_enhanced' : 'heuristic_only',
    ms: durationMs,
    api_version: '2025-10-02-perplexity-reddit-analysis'
  };
  // Add high-level evidence summary for user transparency
  (response as any).evidence = {
    real_post_count: realPostsOnly.length,
    synthetic_post_count: fetchedPosts.filter(p => p.source === 'synthetic').length,
    subreddits_used: Array.from(new Set(fetchedPosts.map(p => p.subreddit))).slice(0,10),
    sample_reddit_posts: realPostsOnly.slice(0,5).map(p => ({ 
      title: p.title, 
      selftext: p.selftext || '', 
      score: p.score, 
      num_comments: p.num_comments, 
      subreddit: p.subreddit,
      permalink: p.permalink || '',
      signals: (p as any).signals || {},
      content_length: (p as any).content_length || 0,
      engagement_ratio: (p as any).engagement_ratio || 0,
      source: p.source || 'reddit'
    }))
  };
  // Set transparency indicators based on data sources
  if (realPostsOnly.length === 0) {
    if (enriched && hasPerplexityKey) {
      (response as any).analysis_confidence = 'ai_enhanced';
      (response as any).data_source = 'ai_synthetic';  
      (response as any).notes = `üî• AI-ENHANCED ANALYSIS: Using Perplexity for sophisticated market validation. Real Reddit data would enhance accuracy further.`;
      (response as any).upgrade_message = `üí° Pro Tip: Reddit OAuth + Perplexity = Ultimate market insights! Set up Reddit API for even deeper analysis.`;
    } else {
      (response as any).analysis_confidence = 'demo_mode';
      (response as any).data_source = 'synthetic_only';
      (response as any).notes = '‚ö†Ô∏è BASIC MODE: Using heuristic analysis. Enable Perplexity + Reddit OAuth for premium insights.';
      (response as any).upgrade_message = 'üîë Unlock AI-powered analysis! Add Perplexity API key and Reddit OAuth for real market intelligence.';
    }
  } else if (realPostsOnly.length > 0 && enriched && hasPerplexityKey) {
    // This is the premium experience: Real Reddit data + AI analysis
    (response as any).analysis_confidence = 'premium_enhanced';
    (response as any).data_source = 'reddit_plus_ai';
    (response as any).notes = `üî• PREMIUM ANALYSIS: Combining ${realPostsOnly.length} real Reddit discussions with Perplexity intelligence for maximum accuracy.`;
    (response as any).upgrade_message = '‚ú® You\'re getting the best possible analysis! Real data + AI insights = Market validation gold standard.';
  } else if (realPostsOnly.length < 4) {
    (response as any).analysis_confidence = 'low';
    (response as any).data_source = 'limited_real';
    (response as any).notes = `Limited real discussion data (${realPostsOnly.length} posts). Supplemented with synthetic data.`;
  } else if (realPostsOnly.length < 10) {
    (response as any).analysis_confidence = 'medium';
    (response as any).data_source = 'mixed_real_synthetic';
    (response as any).notes = `Analysis based on ${realPostsOnly.length} real posts plus synthetic data.`;
  } else {
    (response as any).analysis_confidence = 'high';
    (response as any).data_source = 'real_reddit_data';
    (response as any).notes = `High confidence analysis based on ${realPostsOnly.length} real Reddit discussions.`;
  }

  // Final safeguard: ensure consistency between analysis_confidence and data_source
  if ((response as any).analysis_confidence === 'ai_enhanced' && (response as any).data_source !== 'ai_synthetic') {
    const originalSource = (response as any).data_source;
    (response as any).data_source = 'ai_synthetic';
    (response as any).debug = {
      ...((response as any).debug || {}),
      normalized_data_source: true,
      original_data_source: originalSource,
      normalization_reason: 'analysis_confidence=ai_enhanced requires data_source=ai_synthetic'
    };
    (response as any).notes = ((response as any).notes || '') + ' \n(Backend normalization applied to ensure AI transparency.)';
  }
  return response;
  
  } catch (error) {
    console.error('‚ùå Error in performRealAnalysis:', error);
    throw error;
  }
}

function buildBaseResponse(params: { idea: string; industry?: string; targetAudience?: string; isAI: boolean; isFitness: boolean; tokens: string[]; keywords: string[]; subreddits: string[]; pain_points: any[]; app_ideas: any[]; competitors: any[]; revenue_models: any[]; fetchedPosts: RawRedditPost[]; }) {
  const { isAI, isFitness, keywords, subreddits, pain_points, app_ideas, competitors, revenue_models, fetchedPosts, tokens } = params;
  const realPosts = fetchedPosts.filter(p => p.source === 'reddit');
  console.log(`üìä Calculating scores from ${realPosts.length} REAL posts (total including synthetic: ${fetchedPosts.length})...`);
  
  // Advanced sentiment analysis based on real Reddit engagement
  const postsForScoring = realPosts.length ? realPosts : fetchedPosts; // fallback if no real
  const totalScore = postsForScoring.reduce((sum, p) => sum + p.score, 0);
  const totalComments = postsForScoring.reduce((sum, p) => sum + p.num_comments, 0);
  const avgScore = postsForScoring.length ? totalScore / postsForScoring.length : 15;
  const avgComments = postsForScoring.length ? totalComments / postsForScoring.length : 3;
  
  // High engagement posts indicate market interest (using postsForScoring set)
  const highEngagementPosts = postsForScoring.filter(p => p.score > avgScore && p.num_comments > avgComments).length;
  const engagementRatio = postsForScoring.length ? highEngagementPosts / postsForScoring.length : 0.3;
  
  // Calculate realistic sentiment based on actual data
  const baseEnthusiasm = Math.min(65, Math.round(avgScore * 1.2 + avgComments * 3));
  const engagementBoost = Math.round(engagementRatio * 25);
  const enthusiasm = clamp(baseEnthusiasm + engagementBoost, 25, 75);
  
  const baseFrustration = Math.round(pain_points.length * 8);
  const lowEngagementPenalty = postsForScoring.length < 5 ? 10 : 0;
  const frustration = clamp(baseFrustration + lowEngagementPenalty, 10, 45);
  
  const mixed = clamp(100 - enthusiasm - frustration, 15, 60);

  const sentiment_data = [
    { name: 'Enthusiastic', value: enthusiasm, color: 'hsl(var(--chart-2))', description: 'Strong market interest and engagement' },
    { name: 'Curious/Mixed', value: mixed, color: 'hsl(var(--chart-3))', description: 'Questions and evaluation discussions' },
    { name: 'Frustrated', value: frustration, color: 'hsl(var(--destructive))', description: 'Pain points and unmet needs identified' }
  ];

  // Advanced multi-factor scoring system with market intelligence
  const avgScoreNormalized = Math.log10(Math.max(1, avgScore)) / Math.log10(100); // Log scale for Reddit scores
  const avgCommentsNormalized = Math.log10(Math.max(1, avgComments)) / Math.log10(50);
  const postVolumeScore = Math.min(1.0, postsForScoring.length / 15); // More REAL posts = better signal
  
  // Enhanced content quality and market signal indicators
  const hasDetailedDiscussions = postsForScoring.length ? postsForScoring.filter(p => (p.selftext?.length || 0) > 100).length / postsForScoring.length : 0;
  const hasHighEngagement = postsForScoring.length ? postsForScoring.filter(p => p.score > avgScore * 1.5 || p.num_comments > avgComments * 2).length / postsForScoring.length : 0;
  
  // Market validation signals from enhanced post metadata
  const problemSignalStrength = postsForScoring.length ? postsForScoring.filter(p => (p as any).signals?.is_problem_focused).length / postsForScoring.length : 0;
  const solutionSeekingSignal = postsForScoring.length ? postsForScoring.filter(p => (p as any).signals?.is_solution_seeking).length / postsForScoring.length : 0;
  const costMentionSignal = postsForScoring.length ? postsForScoring.filter(p => (p as any).signals?.mentions_cost).length / postsForScoring.length : 0;
  const competitorMentionSignal = postsForScoring.length ? postsForScoring.filter(p => (p as any).signals?.mentions_competitors).length / postsForScoring.length : 0;
  
  // Engagement quality metrics
  const avgEngagementRatio = postsForScoring.length ? postsForScoring.reduce((sum, p) => sum + ((p as any).engagement_ratio || 0), 0) / postsForScoring.length : 0;
  const recentPostsRatio = postsForScoring.length ? postsForScoring.filter(p => ((p as any).post_age_days || 365) < 30).length / postsForScoring.length : 0;
  
  // Market opportunity indicators
  const marketOpportunityScore = (problemSignalStrength * 0.3 + solutionSeekingSignal * 0.25 + costMentionSignal * 0.2 + competitorMentionSignal * 0.15 + avgEngagementRatio * 0.1);
  
  console.log(`üîç Market Signals: Problems=${(problemSignalStrength*100).toFixed(0)}% Solutions=${(solutionSeekingSignal*100).toFixed(0)}% Cost=${(costMentionSignal*100).toFixed(0)}% Competitors=${(competitorMentionSignal*100).toFixed(0)}% Recent=${(recentPostsRatio*100).toFixed(0)}%`);
  
  // Market trend multipliers
  const trendMultipliers = {
    ai: isAI ? 1.6 : 1.0,           // AI is hot right now
    fitness: isFitness ? 1.3 : 1.0,  // Fitness tech growing
    general: 1.0
  };
  const trendBonus = Math.max(...Object.values(trendMultipliers));
  
  // Keyword relevance scoring - more relevant keywords = higher confidence
  const keywordRelevanceScore = Math.min(1.0, keywords.length / 8);
  
  // Pain point opportunities
  const painPointOpportunity = Math.min(1.0, pain_points.length / 3);
  
  // Combine all factors with enhanced market intelligence weighting
  const engagementComponent = (avgScoreNormalized * 0.3 + avgCommentsNormalized * 0.25 + hasHighEngagement * 0.25 + avgEngagementRatio * 0.2);
  const volumeComponent = (postVolumeScore * 0.5 + hasDetailedDiscussions * 0.3 + recentPostsRatio * 0.2);
  const marketComponent = (keywordRelevanceScore * 0.3 + painPointOpportunity * 0.3 + marketOpportunityScore * 0.4) * trendBonus;
  
  // Final scoring with sophisticated market validation weighting
  const baseScore = (marketComponent * 0.45 + engagementComponent * 0.35 + volumeComponent * 0.2) * 10;
  
  // Realistic market-based scoring system
  const ideaHash = params.idea.split('').reduce((acc: number, char: string) => acc + char.charCodeAt(0), 0);
  const consistentVariation = (ideaHash % 100) / 100; // 0-1 based on idea content for consistency
  
  // Detect additional market categories for scoring
  const isSaaS = tokens.some(t => ['saas','software','platform','dashboard','api','integration','subscription','cloud'].includes(t));
  const isProductivity = tokens.some(t => ['productivity','efficient','organize','manage','task','workflow','remote','collaboration'].includes(t));
  const isDesign = tokens.some(t => ['design','ui','ux','interface','prototype','figma','creative','brand'].includes(t));
  const isMarketing = tokens.some(t => ['marketing','social','media','brand','advertising','seo','content','influencer'].includes(t));
  const isRealEstate = tokens.some(t => ['real','estate','property','rent','lease','apartment','house','landlord'].includes(t));
  const isEdu = tokens.some(t => ['edu','education','learning','course','tutor','school','teach','student','university','study'].includes(t));

  // Market maturity penalties/bonuses based on competition and saturation
  const marketMaturityMultiplier = 
    isAI ? 0.8 : // AI market is saturated, harder to break through
    isFitness ? 0.75 : // Fitness market is crowded
    isSaaS ? 0.85 : // SaaS market is competitive
    isMarketing ? 0.7 : // Marketing tools are oversaturated
    isProductivity ? 0.8 : // Productivity market is crowded
    isRealEstate ? 1.1 : // Real estate tech has opportunities
    isEdu ? 1.0 : // Education market is stable
    isDesign ? 0.9 : // Design tools market is competitive
    1.0; // Other markets
  
  // Data quality scoring - penalize lack of real data heavily
  const realDataQuality = realPosts.length > 0 ? 
    Math.min(1.0, realPosts.length / 8) : // Full points for 8+ real posts
    0.3; // Major penalty for no real data
  
  // Market signal strength calculation with pain point validation
  const painPointQuality = pain_points.length > 0 ? 
    (pain_points.reduce((sum: number, p: any) => sum + (p.frequency || 50), 0) / pain_points.length) / 100 :
    0.2; // Low default if no pain points detected
  
  const marketSignalScore = (
    problemSignalStrength * 0.35 + // Problems are most important
    solutionSeekingSignal * 0.25 + // Active seeking is valuable
    costMentionSignal * 0.2 + // Willingness to pay
    competitorMentionSignal * 0.1 + // Market awareness
    painPointQuality * 0.1 // Pain point strength
  );
  
  // Content depth and engagement quality
  const contentQualityScore = (
    hasDetailedDiscussions * 0.4 + 
    hasHighEngagement * 0.3 +
    avgEngagementRatio * 0.3
  );
  
  // Calculate base market opportunity score (0-10 scale)
  const marketOpportunityBase = (
    marketSignalScore * 0.4 + // Market need signals
    contentQualityScore * 0.25 + // Discussion quality
    realDataQuality * 0.2 + // Data reliability
    (keywordRelevanceScore * painPointOpportunity) * 0.15 // Keyword relevance √ó pain points
  ) * 10;
  
  // Apply market maturity and trend adjustments
  const trendAdjustedScore = marketOpportunityBase * marketMaturityMultiplier * trendBonus;
  
  // Add idea-specific variation (consistent per idea)
  const ideaSpecificAdjustment = (consistentVariation - 0.5) * 2; // -1 to +1 range
  
  // Final scores with realistic distribution (2-8 typical range, exceptional cases can go higher)
  const overall_score = clamp(trendAdjustedScore + ideaSpecificAdjustment, 2.0, 8.5);
  const viability_score = clamp(overall_score + (consistentVariation - 0.5) * 1.0, 2.0, 8.5);
  
  console.log(`üìà Detailed Scoring Breakdown:`);
  console.log(`   Real Posts: ${realPosts.length}/${fetchedPosts.length} (${(realDataQuality*100).toFixed(0)}% data quality)`);
  console.log(`   Market Signals: ${(marketSignalScore*100).toFixed(0)}% Content Quality: ${(contentQualityScore*100).toFixed(0)}%`);
  console.log(`   Base Market Score: ${marketOpportunityBase.toFixed(1)} Trend Bonus: ${trendBonus.toFixed(2)}x`);
  console.log(`   Market Maturity: ${marketMaturityMultiplier.toFixed(2)}x Final Score: ${overall_score.toFixed(1)}/10`)

  // Realistic market interest calculation based on actual signals
  const marketInterestLevel = Math.round(
    (marketSignalScore * 40) + // Market signals contribute 0-40 points
    (contentQualityScore * 30) + // Content quality contributes 0-30 points  
    (realDataQuality * 20) + // Real data contributes 0-20 points
    (overall_score * 1.2) // Overall score contributes some points
  );

  const google_trends = [
    {
      keyword: keywords[0] || tokens[0] || 'startup',
      trend_direction: overall_score > 6.5 ? 'rising' : overall_score > 4.5 ? 'stable' : 'declining',
      interest_level: clamp(marketInterestLevel, 10, 95),
      related_queries: keywords.slice(1,4)
    }
  ];

  return {
    idea: params.idea,
    keywords,
    subreddits,
    sentiment_data,
    pain_points,
    app_ideas: app_ideas.map(a => ({
      title: a.title,
      description: a.description,
      market_validation: a.market_validation || (overall_score > 6.5 ? 'high' : overall_score > 4.5 ? 'medium' : 'low'),
      difficulty: a.difficulty || (isAI ? 'hard' : isFitness ? 'medium' : 'easy')
    })),
    google_trends,
    icp: {
      demographics: { age_range: isFitness ? '25-45' : isAI ? '28-40':'25-40', gender: 'Mixed', income_level: isAI ? 'High':'Middle to High', education: 'College Graduate' },
      psychographics: { interests: keywords.slice(0,3), values: ['Innovation','Efficiency','Growth'], lifestyle: isAI ? 'Tech-forward professional' : isFitness ? 'Health-conscious achiever':'Modern digital native' },
      behavioral: { pain_points: pain_points.map(p=>p.title), preferred_channels: ['Reddit','Communities','Search'], buying_behavior: 'Research & community influenced' }
    },
    problem_statements: [
      { problem: `${params.targetAudience || 'Users'} face recurring challenges related to ${params.idea.toLowerCase().split(' ').slice(0,6).join(' ')}`,
        impact: 'Leads to inefficiency and lost opportunity',
        evidence: pain_points.slice(0,3).map(p=>p.title),
        market_size: `Growing ${params.industry || 'technology'} interest signaled by community discussions` }
    ],
    financial_risks: [
      { risk_type:'Market Adoption', severity: overall_score<6 ? 'high': overall_score<8 ? 'medium':'low', description:'Need to convert curiosity into sustained usage', mitigation_strategy:'Ship focused MVP, rapid iteration, prove retention metrics' }
    ],
    competitors: competitors.map(c => ({
      name: c.name,
      description: c.description || 'Alternative solution in adjacent space',
      strengths: c.strengths || ['Brand'],
      weaknesses: c.weaknesses || ['Limited specialization'],
      market_share: c.market_share || 'Fragmented',
      pricing_model: c.pricing_model || 'Subscription'
    })),
    revenue_models: revenue_models.map(r => ({
      model_type: r.model_type,
      description: r.description,
      pros: r.pros || ['Scalable'],
      cons: r.cons || ['Churn risk'],
      implementation_difficulty: r.implementation_difficulty || (isAI ? 'hard':'medium'),
      potential_revenue: r.potential_revenue || (overall_score>7 ? 'High': overall_score>5 ? 'Medium':'Moderate')
    })),
    market_interest_level: overall_score > 6.5 ? 'high' : overall_score > 4.5 ? 'medium' : 'low',
    total_posts_analyzed: fetchedPosts.length,
    overall_score,
    viability_score
  };
}
// touch 2025-09-25T19:19:56.3254035+05:30


